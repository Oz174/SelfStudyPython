{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook to be run on google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generating a large synthetic dataset\n",
    "np.random.seed(42)\n",
    "data = {\n",
    "    'A': np.random.rand(1000000),\n",
    "    'B': np.random.rand(1000000),\n",
    "    'C': np.random.randint(0, 100, 1000000),\n",
    "    'D': np.random.choice(['X', 'Y', 'Z'], 1000000)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "# Save dataset to a CSV file\n",
    "df.to_csv('Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Reading data\n",
    "start_time = time.time()\n",
    "df = pd.read_csv('Data.csv')\n",
    "read_time_pandas = time.time() - start_time\n",
    "\n",
    "# Groupby operation\n",
    "start_time = time.time()\n",
    "grouped_df = df.groupby('D').mean()\n",
    "groupby_time_pandas = time.time() - start_time\n",
    "\n",
    "# Descriptive statistics\n",
    "start_time = time.time()\n",
    "desc_stats_pandas = df.describe()\n",
    "desc_time_pandas = time.time() - start_time\n",
    "read_time_pandas, groupby_time_pandas, desc_time_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FireDuck Pandas\n",
    "import fireducks.pandas as pd\n",
    "import time\n",
    "\n",
    "# Reading data\n",
    "start_time = time.time()\n",
    "df_fd = fpd.read_csv('Data.csv')\n",
    "read_time_fireduck = time.time() - start_time\n",
    "\n",
    "# Groupby operation\n",
    "start_time = time.time()\n",
    "grouped_df_fd = df_fd.groupby('D').mean()\n",
    "groupby_time_fireduck = time.time() - start_time\n",
    "\n",
    "# Descriptive statistics\n",
    "start_time = time.time()\n",
    "desc_stats_fireduck = df_fd.describe()\n",
    "desc_time_fireduck = time.time() - start_time\n",
    "read_time_fireduck, groupby_time_fireduck, desc_time_fireduck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "# Reading data\n",
    "mem_usage_pandas = memory_usage((pd.read_csv, ('Data.csv',)))\n",
    "max_mem_usage_pandas = max(mem_usage_pandas)\n",
    "\n",
    "# Groupby operation\n",
    "df = pd.read_csv('Data.csv')\n",
    "mem_usage_pandas_groupby = memory_usage((df.groupby, ('D',)))\n",
    "max_mem_usage_pandas_groupby = max(mem_usage_pandas_groupby)\n",
    "\n",
    "# Descriptive statistics\n",
    "mem_usage_pandas_desc = memory_usage((df.describe,))\n",
    "max_mem_usage_pandas_desc = max(mem_usage_pandas_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fireduck_pandas as fpd\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "\n",
    "# Reading data\n",
    "mem_usage_fireduck = memory_usage((fpd.read_csv, ('Data.csv')))\n",
    "max_mem_usage_fireduck = max(mem_usage_fireduck)\n",
    "\n",
    "# Groupby operation\n",
    "df_fd = fpd.read_csv('Data.csv')\n",
    "mem_usage_fireduck_groupby = memory_usage((df_fd.groupby, ('D',)))\n",
    "max_mem_usage_fireduck_groupby = max(mem_usage_fireduck_groupby)\n",
    "\n",
    "# Descriptive statistics\n",
    "mem_usage_fireduck_desc = memory_usage((df_fd.describe,))\n",
    "max_mem_usage_fireduck_desc = max(mem_usage_fireduck_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Performance data\n",
    "operations = ['Read CSV', 'Groupby Mean', 'Describe']\n",
    "normal_pandas_times = [read_time_pandas, groupby_time_pandas, \n",
    "                      desc_time_pandas]\n",
    "fireduck_pandas_times = [read_time_fireduck, groupby_time_fireduck, \n",
    "                        desc_time_fireduck]\n",
    "\n",
    "# Memory usage data\n",
    "normal_pandas_mem = [max_mem_usage_pandas, max_mem_usage_pandas_groupby, \n",
    "                     max_mem_usage_pandas_desc]\n",
    "fireduck_pandas_mem = [max_mem_usage_fireduck, max_mem_usage_fireduck_groupby,\n",
    "                       max_mem_usage_fireduck_desc]\n",
    "\n",
    "# Plotting speed performance\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(operations, normal_pandas_times, width=0.4, label='Normal Pandas',\n",
    "        align='center')\n",
    "plt.bar(operations, fireduck_pandas_times, width=0.4, label='FireDuck Pandas',\n",
    "        align='edge')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.title('Speed Performance Comparison')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting memory usage\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(operations, normal_pandas_mem, width=0.4, label='Normal Pandas',\n",
    "        align='center')\n",
    "plt.bar(operations, fireduck_pandas_mem, width=0.4, label='FireDuck Pandas',\n",
    "        align='edge')\n",
    "plt.ylabel('Memory Usage (MB)')\n",
    "plt.title('Memory Usage Comparison')\n",
    "plt.legend()\n",
    "\n",
    "# Displaying the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the Contenders\n",
    "### Performance\n",
    "Normal Pandas performs well for datasets that fit into memory, making it ideal for small to medium-sized data. However, it can struggle with very large datasets. FireDuck Pandas is designed to handle larger datasets more efficiently, making it a better choice for big data scenarios.\n",
    "\n",
    "### API and Usability\n",
    "One of the strengths of Normal Pandas is its intuitive and easy-to-use API, which has made it very popular. FireDuck Pandas maintains a similar API, which means that users familiar with Normal Pandas can easily transition to using FireDuck Pandas with minimal learning curve.\n",
    "\n",
    "### Community and Ecosystem\n",
    "Normal Pandas has a vast user base and a rich ecosystem of libraries and resources. FireDuck Pandas is newer and still growing its community, but it benefits from compatibility with the existing pandas ecosystem.\n",
    "\n",
    "### Conclusion\n",
    "FireDuck Pandas offers way better performance and Somewhat Similar Memory Management for large datasets compared to Normal Pandas. While Normal Pandas remains a great choice for smaller datasets and is backed by a strong community, FireDuck Pandas is an excellent alternative for handling big data scenarios more effectively.\n",
    "\n",
    "With these insights, you can make an informed decision on which library to use based on your data size and performance requirements. Whether you stick with the tried-and-true Normal Pandas or explore the high-performance FireDuck Pandas, both libraries offer robust tools to tackle your data analysis needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
